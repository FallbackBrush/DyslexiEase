{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "from math import log2\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET                 = r\"D:\\gokul\\FINAL CAPSTONE\\DyslexiEase\\Data\\Processsed\\test.mp4\"\n",
    "START_TRAIN_AT_IMG_SIZE = 32\n",
    "DEVICE                  = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "LEARNING_RATE           = 1e-3\n",
    "BATCH_SIZES             = [32, 32, 32, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]\n",
    "image_size              = 512\n",
    "CHANNELS_IMG            = 3\n",
    "Z_DIM                   = 256  \n",
    "IN_CHANNELS             = 256  \n",
    "LAMBDA_GP               = 10\n",
    "PROGRESSIVE_EPOCHS      = [30] * len(BATCH_SIZES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loader(image_size):\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize((image_size, image_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.Normalize(\n",
    "                [0.5 for _ in range(CHANNELS_IMG)],\n",
    "                [0.5 for _ in range(CHANNELS_IMG)],\n",
    "            )#,a\n",
    "        ]\n",
    "    )\n",
    "    batch_size = BATCH_SIZES[int(log2(image_size / 4))]\n",
    "    dataset = datasets.ImageFolder(root=DATASET, transform=transform)\n",
    "    loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    return loader, dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def check_loader():\n",
    "    loader,_ = get_loader(128)\n",
    "    cloth ,_ = next(iter(loader))\n",
    "    _, ax    = plt.subplots(3,3, figsize=(8,8))\n",
    "    #plt.suptitle('Some real samples', fontsize=15, fontweight='bold')\n",
    "    ind = 0 \n",
    "    for k in range(3):\n",
    "        for kk in range(3):\n",
    "            ind += 1\n",
    "            #ax[k][kk].imshow((cloth[ind].permute(1,2,0)+1)/2) \n",
    "check_loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "factors = [1, 1, 1, 1, 1 / 2, 1 / 4, 1 / 8, 1 / 16, 1 / 32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WSConv2d(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self, in_channels, out_channels, kernel_size=3, stride=1, padding=1,\n",
    "    ):\n",
    "        super(WSConv2d, self).__init__()\n",
    "        self.conv      = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        self.scale     = (2 / (in_channels * (kernel_size ** 2))) ** 0.5\n",
    "        self.bias      = self.conv.bias #Copy the bias of the current column layer\n",
    "        self.conv.bias = None      #Remove the bias\n",
    "\n",
    "        # initialize conv layer\n",
    "        nn.init.normal_(self.conv.weight)\n",
    "        nn.init.zeros_(self.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x * self.scale) + self.bias.view(1, self.bias.shape[0], 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PixelNorm(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PixelNorm, self).__init__()\n",
    "        self.epsilon = 1e-8\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x / torch.sqrt(torch.mean(x ** 2, dim=1, keepdim=True) + self.epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, use_pixelnorm=True):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.use_pn = use_pixelnorm\n",
    "        self.conv1  = WSConv2d(in_channels, out_channels)\n",
    "        self.conv2  = WSConv2d(out_channels, out_channels)\n",
    "        self.leaky  = nn.LeakyReLU(0.2)\n",
    "        self.pn     = PixelNorm()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.leaky(self.conv1(x))\n",
    "        x = self.pn(x) if self.use_pn else x\n",
    "        x = self.leaky(self.conv2(x))\n",
    "        x = self.pn(x) if self.use_pn else x\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim, in_channels, img_channels=3):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        # initial takes 1x1 -> 4x4\n",
    "        self.initial = nn.Sequential(\n",
    "            PixelNorm(),\n",
    "            nn.ConvTranspose2d(z_dim, in_channels, 4, 1, 0),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            WSConv2d(in_channels, in_channels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            PixelNorm(),\n",
    "        )\n",
    "\n",
    "        self.initial_rgb = WSConv2d(\n",
    "            in_channels, img_channels, kernel_size=1, stride=1, padding=0\n",
    "        )\n",
    "        self.prog_blocks, self.rgb_layers = (\n",
    "            nn.ModuleList([]),\n",
    "            nn.ModuleList([self.initial_rgb]),\n",
    "        )\n",
    "\n",
    "        for i in range(\n",
    "            len(factors) - 1\n",
    "        ):  # -1 to prevent index error because of factors[i+1]\n",
    "            conv_in_c  = int(in_channels * factors[i])\n",
    "            conv_out_c = int(in_channels * factors[i + 1])\n",
    "            self.prog_blocks.append(ConvBlock(conv_in_c, conv_out_c))\n",
    "            self.rgb_layers.append(\n",
    "                WSConv2d(conv_out_c, img_channels, kernel_size=1, stride=1, padding=0)\n",
    "            )\n",
    "\n",
    "    def fade_in(self, alpha, upscaled, generated):\n",
    "        # alpha should be scalar within [0, 1], and upscale.shape == generated.shape\n",
    "        return torch.tanh(alpha * generated + (1 - alpha) * upscaled)\n",
    "\n",
    "    def forward(self, x, alpha, steps):\n",
    "        out = self.initial(x)\n",
    "\n",
    "        if steps == 0:\n",
    "            return self.initial_rgb(out)\n",
    "\n",
    "        for step in range(steps):\n",
    "            upscaled = F.interpolate(out, scale_factor=2, mode=\"nearest\")\n",
    "            out = self.prog_blocks[step](upscaled)\n",
    "\n",
    "        # The number of channels in upscale will stay the same, while\n",
    "        # out which has moved through prog_blocks might change. To ensure\n",
    "        # we can convert both to rgb we use different rgb_layers\n",
    "        # (steps-1) and steps for upscaled, out respectively\n",
    "        final_upscaled = self.rgb_layers[steps - 1](upscaled)\n",
    "        final_out = self.rgb_layers[steps](out)\n",
    "        return self.fade_in(alpha, final_upscaled, final_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_channels, img_channels=3):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.prog_blocks, self.rgb_layers = nn.ModuleList([]), nn.ModuleList([])\n",
    "        self.leaky = nn.LeakyReLU(0.2)\n",
    "\n",
    "        # here we work back ways from factors because the discriminator\n",
    "        # should be mirrored from the generator. So the first prog_block and\n",
    "        # rgb layer we append will work for input size 1024x1024, then 512->256-> etc\n",
    "        for i in range(len(factors) - 1, 0, -1):\n",
    "            conv_in = int(in_channels * factors[i])\n",
    "            conv_out = int(in_channels * factors[i - 1])\n",
    "            self.prog_blocks.append(ConvBlock(conv_in, conv_out, use_pixelnorm=False))\n",
    "            self.rgb_layers.append(\n",
    "                WSConv2d(img_channels, conv_in, kernel_size=1, stride=1, padding=0)\n",
    "            )\n",
    "\n",
    "        # perhaps confusing name \"initial_rgb\" this is just the RGB layer for 4x4 input size\n",
    "        # did this to \"mirror\" the generator initial_rgb\n",
    "        self.initial_rgb = WSConv2d(\n",
    "            img_channels, in_channels, kernel_size=1, stride=1, padding=0\n",
    "        )\n",
    "        self.rgb_layers.append(self.initial_rgb)\n",
    "        self.avg_pool = nn.AvgPool2d(\n",
    "            kernel_size=2, stride=2\n",
    "        )  # down sampling using avg pool\n",
    "\n",
    "        # this is the block for 4x4 input size\n",
    "        self.final_block = nn.Sequential(\n",
    "            # +1 to in_channels because we concatenate from MiniBatch std\n",
    "            WSConv2d(in_channels + 1, in_channels, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            WSConv2d(in_channels, in_channels, kernel_size=4, padding=0, stride=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            WSConv2d(\n",
    "                in_channels, 1, kernel_size=1, padding=0, stride=1\n",
    "            ),  # we use this instead of linear layer\n",
    "        )\n",
    "\n",
    "    def fade_in(self, alpha, downscaled, out):\n",
    "        \"\"\"Used to fade in downscaled using avg pooling and output from CNN\"\"\"\n",
    "        # alpha should be scalar within [0, 1], and upscale.shape == generated.shape\n",
    "        return alpha * out + (1 - alpha) * downscaled\n",
    "\n",
    "    def minibatch_std(self, x):\n",
    "        batch_statistics = (\n",
    "            torch.std(x, dim=0).mean().repeat(x.shape[0], 1, x.shape[2], x.shape[3])\n",
    "        )\n",
    "        # we take the std for each example (across all channels, and pixels) then we repeat it\n",
    "        # for a single channel and concatenate it with the image. In this way the discriminator\n",
    "        # will get information about the variation in the batch/image\n",
    "        return torch.cat([x, batch_statistics], dim=1)\n",
    "\n",
    "    def forward(self, x, alpha, steps):\n",
    "        # where we should start in the list of prog_blocks, maybe a bit confusing but\n",
    "        # the last is for the 4x4. So example let's say steps=1, then we should start\n",
    "        # at the second to last because input_size will be 8x8. If steps==0 we just\n",
    "        # use the final block\n",
    "        cur_step = len(self.prog_blocks) - steps\n",
    "\n",
    "        # convert from rgb as initial step, this will depend on\n",
    "        # the image size (each will have it's on rgb layer)\n",
    "        out = self.leaky(self.rgb_layers[cur_step](x))\n",
    "\n",
    "        if steps == 0:  # i.e, image is 4x4\n",
    "            out = self.minibatch_std(out)\n",
    "            return self.final_block(out).view(out.shape[0], -1)\n",
    "\n",
    "        # because prog_blocks might change the channels, for down scale we use rgb_layer\n",
    "        # from previous/smaller size which in our case correlates to +1 in the indexing\n",
    "        downscaled = self.leaky(self.rgb_layers[cur_step + 1](self.avg_pool(x)))\n",
    "        out = self.avg_pool(self.prog_blocks[cur_step](out))\n",
    "\n",
    "        # the fade_in is done first between the downscaled and the input\n",
    "        # this is opposite from the generator\n",
    "        out = self.fade_in(alpha, downscaled, out)\n",
    "\n",
    "        for step in range(cur_step + 1, len(self.prog_blocks)):\n",
    "            out = self.prog_blocks[step](out)\n",
    "            out = self.avg_pool(out)\n",
    "\n",
    "        out = self.minibatch_std(out)\n",
    "        return self.final_block(out).view(out.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_penalty(critic, real, fake, alpha, train_step, device=\"cpu\"):\n",
    "    BATCH_SIZE, C, H, W = real.shape\n",
    "    beta = torch.rand((BATCH_SIZE, 1, 1, 1)).repeat(1, C, H, W).to(device)\n",
    "    interpolated_images = real * beta + fake.detach() * (1 - beta)\n",
    "    interpolated_images.requires_grad_(True)\n",
    "\n",
    "    # Calculate critic scores\n",
    "    mixed_scores = critic(interpolated_images, alpha, train_step)\n",
    " \n",
    "    # Take the gradient of the scores with respect to the images\n",
    "    gradient = torch.autograd.grad(\n",
    "        inputs=interpolated_images,\n",
    "        outputs=mixed_scores,\n",
    "        grad_outputs=torch.ones_like(mixed_scores),\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "    )[0]\n",
    "    gradient = gradient.view(gradient.shape[0], -1)\n",
    "    gradient_norm = gradient.norm(2, dim=1)\n",
    "    gradient_penalty = torch.mean((gradient_norm - 1) ** 2)\n",
    "    return gradient_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_examples(gen, steps, n=100):\n",
    "\n",
    "    gen.eval()\n",
    "    alpha = 1.0\n",
    "    for i in range(n):\n",
    "        with torch.no_grad():\n",
    "            noise = torch.randn(1, Z_DIM, 1, 1).to(DEVICE)\n",
    "            img = gen(noise, alpha, steps)\n",
    "            \n",
    "            if not os.path.exists(f'saved_examples/step{steps}'):\n",
    "                os.makedirs(f'saved_examples/step{steps}')\n",
    "            save_image(img*0.5+0.5, f\"saved_examples/step{steps}/img_{i}.png\")\n",
    "    gen.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmarks = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(\n",
    "    critic,\n",
    "    gen,\n",
    "    loader,\n",
    "    dataset,\n",
    "    step,\n",
    "    alpha,\n",
    "    opt_critic,\n",
    "    opt_gen,\n",
    "):\n",
    "    loop = tqdm(loader, leave=True)\n",
    "    for batch_idx, (real, _) in enumerate(loop):\n",
    "        real = real.to(DEVICE)\n",
    "        cur_batch_size = real.shape[0]\n",
    "\n",
    "        # Train Critic: max E[critic(real)] - E[critic(fake)] <-> min -E[critic(real)] + E[critic(fake)]\n",
    "        # which is equivalent to minimizing the negative of the expression\n",
    "        noise = torch.randn(cur_batch_size, Z_DIM, 1, 1).to(DEVICE)\n",
    "\n",
    "        fake = gen(noise, alpha, step)\n",
    "        critic_real = critic(real, alpha, step)\n",
    "        critic_fake = critic(fake.detach(), alpha, step)\n",
    "        gp = gradient_penalty(critic, real, fake, alpha, step, device=DEVICE)\n",
    "        loss_critic = (\n",
    "            -(torch.mean(critic_real) - torch.mean(critic_fake))\n",
    "            + LAMBDA_GP * gp\n",
    "            + (0.001 * torch.mean(critic_real ** 2))\n",
    "        )\n",
    "\n",
    "        critic.zero_grad()\n",
    "        loss_critic.backward()\n",
    "        opt_critic.step()\n",
    "\n",
    "        # Train Generator: max E[critic(gen_fake)] <-> min -E[critic(gen_fake)]\n",
    "        gen_fake = critic(fake, alpha, step)\n",
    "        loss_gen = -torch.mean(gen_fake)\n",
    "\n",
    "        gen.zero_grad()\n",
    "        loss_gen.backward()\n",
    "        opt_gen.step()\n",
    "\n",
    "        # Update alpha and ensure less than 1\n",
    "        alpha += cur_batch_size / (\n",
    "            (PROGRESSIVE_EPOCHS[step] * 0.5) * len(dataset)\n",
    "        )\n",
    "        alpha = min(alpha, 1)\n",
    "\n",
    "        loop.set_postfix(\n",
    "            gp=gp.item(),\n",
    "            loss_critic=loss_critic.item(),\n",
    "        )\n",
    "        \n",
    "\n",
    "    return alpha\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current image size: 32\n",
      "Epoch [1/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:06<00:00,  2.73it/s, gp=0.0611, loss_critic=-15.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:04<00:00,  3.95it/s, gp=0.735, loss_critic=-18]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:05<00:00,  3.47it/s, gp=0.217, loss_critic=-9.59]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:05<00:00,  3.37it/s, gp=0.279, loss_critic=-7]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:04<00:00,  3.88it/s, gp=0.162, loss_critic=-6.85] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:04<00:00,  3.87it/s, gp=0.175, loss_critic=-5.66] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:05<00:00,  3.40it/s, gp=0.0313, loss_critic=-3.41]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:05<00:00,  3.39it/s, gp=0.188, loss_critic=-7.25] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:05<00:00,  3.45it/s, gp=0.1, loss_critic=-6.77]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:05<00:00,  3.47it/s, gp=0.0286, loss_critic=-5.32]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:05<00:00,  3.45it/s, gp=0.0824, loss_critic=-7.59]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:05<00:00,  3.42it/s, gp=0.0602, loss_critic=-5.56]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:04<00:00,  3.87it/s, gp=0.0226, loss_critic=-5.22]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:05<00:00,  3.50it/s, gp=0.057, loss_critic=-4.5]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:05<00:00,  3.49it/s, gp=0.0812, loss_critic=-6.99]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:05<00:00,  3.52it/s, gp=0.0538, loss_critic=-7.47]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:05<00:00,  3.48it/s, gp=0.0585, loss_critic=-5.1] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:05<00:00,  3.46it/s, gp=0.0663, loss_critic=-4.72]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:05<00:00,  3.49it/s, gp=0.121, loss_critic=-6.12] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:05<00:00,  3.44it/s, gp=0.0195, loss_critic=-4.9] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:05<00:00,  3.38it/s, gp=0.0648, loss_critic=-5.65]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:05<00:00,  3.34it/s, gp=0.0762, loss_critic=-4.89]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:05<00:00,  3.34it/s, gp=0.0636, loss_critic=-6.08]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:05<00:00,  3.39it/s, gp=0.0796, loss_critic=-5.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:05<00:00,  3.39it/s, gp=0.0828, loss_critic=-4.64]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:05<00:00,  3.39it/s, gp=0.0245, loss_critic=-4.6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:05<00:00,  3.41it/s, gp=0.0662, loss_critic=-5.41]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:05<00:00,  3.34it/s, gp=0.0565, loss_critic=-4.49]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:05<00:00,  3.35it/s, gp=0.024, loss_critic=-4.49] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:05<00:00,  3.47it/s, gp=0.0663, loss_critic=-5.15]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current image size: 64\n",
      "Epoch [1/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:10<00:00,  1.89it/s, gp=0.23, loss_critic=-10.8]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:10<00:00,  1.88it/s, gp=0.177, loss_critic=-13.3] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:10<00:00,  1.88it/s, gp=0.0705, loss_critic=-10.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:10<00:00,  1.86it/s, gp=0.326, loss_critic=-12.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:10<00:00,  1.87it/s, gp=0.147, loss_critic=-10.7] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:10<00:00,  1.84it/s, gp=0.245, loss_critic=-13.4] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:10<00:00,  1.88it/s, gp=0.353, loss_critic=-13.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:10<00:00,  1.85it/s, gp=0.25, loss_critic=-12.4] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:10<00:00,  1.89it/s, gp=0.225, loss_critic=-11.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:09<00:00,  2.00it/s, gp=0.29, loss_critic=-12.5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:09<00:00,  1.99it/s, gp=0.28, loss_critic=-10.2] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:09<00:00,  1.99it/s, gp=0.166, loss_critic=-10.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:09<00:00,  1.97it/s, gp=0.167, loss_critic=-9.68]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:09<00:00,  1.97it/s, gp=0.324, loss_critic=-13.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:09<00:00,  1.97it/s, gp=0.354, loss_critic=-9.01]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:09<00:00,  1.97it/s, gp=0.256, loss_critic=-12.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:09<00:00,  1.96it/s, gp=0.198, loss_critic=-12.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:09<00:00,  1.97it/s, gp=0.208, loss_critic=-10.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:09<00:00,  1.96it/s, gp=0.204, loss_critic=-12]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:09<00:00,  1.96it/s, gp=0.191, loss_critic=-10.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:09<00:00,  1.97it/s, gp=0.171, loss_critic=-11.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:09<00:00,  1.97it/s, gp=0.209, loss_critic=-10.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:09<00:00,  1.97it/s, gp=0.171, loss_critic=-10.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:09<00:00,  1.96it/s, gp=0.196, loss_critic=-9.16]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:09<00:00,  1.96it/s, gp=0.162, loss_critic=-8.53]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:09<00:00,  1.97it/s, gp=0.201, loss_critic=-10.3] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:09<00:00,  1.97it/s, gp=0.128, loss_critic=-10]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:09<00:00,  1.90it/s, gp=0.16, loss_critic=-7.42] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:10<00:00,  1.83it/s, gp=0.147, loss_critic=-4.63] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:10<00:00,  1.84it/s, gp=0.0949, loss_critic=-6.72]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current image size: 128\n",
      "Epoch [1/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:18<00:00,  1.04it/s, gp=1.01, loss_critic=-10.5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:18<00:00,  1.04it/s, gp=0.428, loss_critic=-15.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:18<00:00,  1.04it/s, gp=0.341, loss_critic=-11]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:18<00:00,  1.04it/s, gp=0.118, loss_critic=-11.7] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:18<00:00,  1.04it/s, gp=0.225, loss_critic=-14.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:18<00:00,  1.04it/s, gp=0.124, loss_critic=-11.1] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:18<00:00,  1.04it/s, gp=0.337, loss_critic=-19.3] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:18<00:00,  1.04it/s, gp=0.11, loss_critic=-12.3]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:18<00:00,  1.04it/s, gp=0.394, loss_critic=-14]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:18<00:00,  1.04it/s, gp=0.217, loss_critic=-11.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:18<00:00,  1.04it/s, gp=0.247, loss_critic=-13.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:18<00:00,  1.05it/s, gp=0.239, loss_critic=-11.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:17<00:00,  1.06it/s, gp=0.243, loss_critic=-13.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:17<00:00,  1.06it/s, gp=0.342, loss_critic=-12.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:18<00:00,  1.05it/s, gp=0.282, loss_critic=-11.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:17<00:00,  1.07it/s, gp=0.297, loss_critic=-10.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:17<00:00,  1.07it/s, gp=0.219, loss_critic=-10.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:17<00:00,  1.07it/s, gp=0.182, loss_critic=-10.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:17<00:00,  1.07it/s, gp=0.227, loss_critic=-12.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:17<00:00,  1.07it/s, gp=0.223, loss_critic=-11.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:17<00:00,  1.07it/s, gp=0.202, loss_critic=-10.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:17<00:00,  1.07it/s, gp=0.273, loss_critic=-10.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:17<00:00,  1.07it/s, gp=0.213, loss_critic=-10.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:17<00:00,  1.07it/s, gp=0.232, loss_critic=-10.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:17<00:00,  1.07it/s, gp=0.198, loss_critic=-11.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:17<00:00,  1.07it/s, gp=0.203, loss_critic=-10.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:17<00:00,  1.07it/s, gp=0.242, loss_critic=-11.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:17<00:00,  1.07it/s, gp=0.217, loss_critic=-12.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:17<00:00,  1.07it/s, gp=0.147, loss_critic=-5.33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:17<00:00,  1.07it/s, gp=0.212, loss_critic=-7.53]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current image size: 256\n",
      "Epoch [1/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [02:01<00:00,  6.39s/it, gp=0.4, loss_critic=-24.3]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [01:56<00:00,  6.11s/it, gp=0.617, loss_critic=-26.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [01:56<00:00,  6.13s/it, gp=0.496, loss_critic=-24.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [01:56<00:00,  6.15s/it, gp=0.616, loss_critic=-28.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [01:59<00:00,  6.28s/it, gp=0.692, loss_critic=-25.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [01:59<00:00,  6.27s/it, gp=0.763, loss_critic=-22]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [01:58<00:00,  6.26s/it, gp=0.653, loss_critic=-33]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [01:57<00:00,  6.17s/it, gp=0.369, loss_critic=-24.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [01:56<00:00,  6.12s/it, gp=1.24, loss_critic=-32.8] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [01:58<00:00,  6.24s/it, gp=0.841, loss_critic=-29.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [01:57<00:00,  6.20s/it, gp=0.631, loss_critic=-31.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [01:56<00:00,  6.11s/it, gp=0.555, loss_critic=-26.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [01:56<00:00,  6.13s/it, gp=0.925, loss_critic=-28.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [01:56<00:00,  6.13s/it, gp=0.895, loss_critic=-47.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [01:57<00:00,  6.20s/it, gp=0.948, loss_critic=-33.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [01:56<00:00,  6.14s/it, gp=0.472, loss_critic=-18.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [01:57<00:00,  6.18s/it, gp=0.658, loss_critic=-23]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [01:57<00:00,  6.20s/it, gp=0.698, loss_critic=-31.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [01:56<00:00,  6.12s/it, gp=0.471, loss_critic=-20.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [01:57<00:00,  6.19s/it, gp=0.907, loss_critic=-32.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [01:56<00:00,  6.15s/it, gp=0.815, loss_critic=-23.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [01:56<00:00,  6.14s/it, gp=0.654, loss_critic=-25.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [01:58<00:00,  6.23s/it, gp=0.508, loss_critic=-24.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [01:59<00:00,  6.28s/it, gp=0.684, loss_critic=-25.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [01:59<00:00,  6.27s/it, gp=0.724, loss_critic=-23.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [01:59<00:00,  6.27s/it, gp=0.614, loss_critic=-23.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [01:59<00:00,  6.28s/it, gp=0.582, loss_critic=-27.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [01:57<00:00,  6.18s/it, gp=0.628, loss_critic=-25.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [01:56<00:00,  6.12s/it, gp=0.675, loss_critic=-27.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [01:57<00:00,  6.20s/it, gp=0.677, loss_critic=-25.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current image size: 512\n",
      "Epoch [1/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/19 [00:15<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 512.00 MiB (GPU 0; 12.00 GiB total capacity; 17.12 GiB already allocated; 0 bytes free; 17.49 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 28\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[0;32m     27\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch [\u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mnum_epochs\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 28\u001b[0m     alpha \u001b[39m=\u001b[39m train_fn(\n\u001b[0;32m     29\u001b[0m         critic,\n\u001b[0;32m     30\u001b[0m         gen,\n\u001b[0;32m     31\u001b[0m         loader,\n\u001b[0;32m     32\u001b[0m         dataset,\n\u001b[0;32m     33\u001b[0m         step,\n\u001b[0;32m     34\u001b[0m         alpha,\n\u001b[0;32m     35\u001b[0m         opt_critic,\n\u001b[0;32m     36\u001b[0m         opt_gen,\n\u001b[0;32m     37\u001b[0m     )\n\u001b[0;32m     38\u001b[0m generate_examples(gen, step, n\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m)\n\u001b[0;32m     41\u001b[0m step \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m  \u001b[39m# progress to the next img size\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[20], line 23\u001b[0m, in \u001b[0;36mtrain_fn\u001b[1;34m(critic, gen, loader, dataset, step, alpha, opt_critic, opt_gen)\u001b[0m\n\u001b[0;32m     21\u001b[0m critic_real \u001b[39m=\u001b[39m critic(real, alpha, step)\n\u001b[0;32m     22\u001b[0m critic_fake \u001b[39m=\u001b[39m critic(fake\u001b[39m.\u001b[39mdetach(), alpha, step)\n\u001b[1;32m---> 23\u001b[0m gp \u001b[39m=\u001b[39m gradient_penalty(critic, real, fake, alpha, step, device\u001b[39m=\u001b[39;49mDEVICE)\n\u001b[0;32m     24\u001b[0m loss_critic \u001b[39m=\u001b[39m (\n\u001b[0;32m     25\u001b[0m     \u001b[39m-\u001b[39m(torch\u001b[39m.\u001b[39mmean(critic_real) \u001b[39m-\u001b[39m torch\u001b[39m.\u001b[39mmean(critic_fake))\n\u001b[0;32m     26\u001b[0m     \u001b[39m+\u001b[39m LAMBDA_GP \u001b[39m*\u001b[39m gp\n\u001b[0;32m     27\u001b[0m     \u001b[39m+\u001b[39m (\u001b[39m0.001\u001b[39m \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39mmean(critic_real \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m))\n\u001b[0;32m     28\u001b[0m )\n\u001b[0;32m     30\u001b[0m critic\u001b[39m.\u001b[39mzero_grad()\n",
      "Cell \u001b[1;32mIn[17], line 8\u001b[0m, in \u001b[0;36mgradient_penalty\u001b[1;34m(critic, real, fake, alpha, train_step, device)\u001b[0m\n\u001b[0;32m      5\u001b[0m interpolated_images\u001b[39m.\u001b[39mrequires_grad_(\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      7\u001b[0m \u001b[39m# Calculate critic scores\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m mixed_scores \u001b[39m=\u001b[39m critic(interpolated_images, alpha, train_step)\n\u001b[0;32m     10\u001b[0m \u001b[39m# Take the gradient of the scores with respect to the images\u001b[39;00m\n\u001b[0;32m     11\u001b[0m gradient \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mgrad(\n\u001b[0;32m     12\u001b[0m     inputs\u001b[39m=\u001b[39minterpolated_images,\n\u001b[0;32m     13\u001b[0m     outputs\u001b[39m=\u001b[39mmixed_scores,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     16\u001b[0m     retain_graph\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m     17\u001b[0m )[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\gokul\\anaconda3\\envs\\capstone\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[16], line 72\u001b[0m, in \u001b[0;36mDiscriminator.forward\u001b[1;34m(self, x, alpha, steps)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[39m# because prog_blocks might change the channels, for down scale we use rgb_layer\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[39m# from previous/smaller size which in our case correlates to +1 in the indexing\u001b[39;00m\n\u001b[0;32m     71\u001b[0m downscaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleaky(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrgb_layers[cur_step \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m](\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mavg_pool(x)))\n\u001b[1;32m---> 72\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mavg_pool(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprog_blocks[cur_step](out))\n\u001b[0;32m     74\u001b[0m \u001b[39m# the fade_in is done first between the downscaled and the input\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[39m# this is opposite from the generator\u001b[39;00m\n\u001b[0;32m     76\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfade_in(alpha, downscaled, out)\n",
      "File \u001b[1;32mc:\\Users\\gokul\\anaconda3\\envs\\capstone\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[11], line 13\u001b[0m, in \u001b[0;36mConvBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     11\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleaky(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv1(x))\n\u001b[0;32m     12\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpn(x) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_pn \u001b[39melse\u001b[39;00m x\n\u001b[1;32m---> 13\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleaky(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv2(x))\n\u001b[0;32m     14\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpn(x) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_pn \u001b[39melse\u001b[39;00m x\n\u001b[0;32m     15\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\gokul\\anaconda3\\envs\\capstone\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[8], line 17\u001b[0m, in \u001b[0;36mWSConv2d.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> 17\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv(x \u001b[39m*\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscale) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias\u001b[39m.\u001b[39mview(\u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 512.00 MiB (GPU 0; 12.00 GiB total capacity; 17.12 GiB already allocated; 0 bytes free; 17.49 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# initialize gen and disc, note: discriminator we called critic,\n",
    "# according to WGAN paper (since it no longer outputs between [0, 1])\n",
    "gen = Generator(\n",
    "    Z_DIM, IN_CHANNELS, img_channels=CHANNELS_IMG\n",
    ").to(DEVICE)\n",
    "critic = Discriminator(\n",
    "    IN_CHANNELS, img_channels=CHANNELS_IMG\n",
    ").to(DEVICE)\n",
    "\n",
    "# initialize optimizers\n",
    "opt_gen = optim.Adam(gen.parameters(), lr=LEARNING_RATE, betas=(0.0, 0.99))\n",
    "opt_critic = optim.Adam(\n",
    "    critic.parameters(), lr=LEARNING_RATE, betas=(0.0, 0.99)\n",
    ")\n",
    "\n",
    "\n",
    "gen.train()\n",
    "critic.train()\n",
    "\n",
    "step = int(log2(START_TRAIN_AT_IMG_SIZE / 4))\n",
    "for num_epochs in PROGRESSIVE_EPOCHS:\n",
    "    alpha = 1e-5  # start with very low alpha, you can start with alpha=0\n",
    "    loader, dataset = get_loader(4 * 2 ** step)  # 4->0, 8->1, 16->2, 32->3, 64 -> 4\n",
    "    print(f\"Current image size: {4 * 2 ** step}\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "        alpha = train_fn(\n",
    "            critic,\n",
    "            gen,\n",
    "            loader,\n",
    "            dataset,\n",
    "            step,\n",
    "            alpha,\n",
    "            opt_critic,\n",
    "            opt_gen,\n",
    "        )\n",
    "    generate_examples(gen, step, n=100)\n",
    "\n",
    "\n",
    "    step += 1  # progress to the next img size"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
